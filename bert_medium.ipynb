{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f3a8fd1-25a9-426d-a6be-c93b750cbcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47a53036-31ab-4374-bf15-a4dca17a7cbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>62cfdd36dcebc86793aa9534</td>\n",
       "      <td>bro im not aa im literally african my tribe co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>62cfdda0dcebc86793aaee87</td>\n",
       "      <td>It drives me crazy! It’s such a struggle eithe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>62cfde28dcebc86793ab60dc</td>\n",
       "      <td>So why they making a big deal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>62cfdd8bdcebc86793aadc15</td>\n",
       "      <td>There’s nothing that makes it any better. We h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>62cfddacdcebc86793aaf7bf</td>\n",
       "      <td>Simply put, fascism needs to be fought against...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       _id  \\\n",
       "0           0  62cfdd36dcebc86793aa9534   \n",
       "1           1  62cfdda0dcebc86793aaee87   \n",
       "2           2  62cfde28dcebc86793ab60dc   \n",
       "3           3  62cfdd8bdcebc86793aadc15   \n",
       "4           4  62cfddacdcebc86793aaf7bf   \n",
       "\n",
       "                                             comment  offensive  \n",
       "0  bro im not aa im literally african my tribe co...          0  \n",
       "1  It drives me crazy! It’s such a struggle eithe...          0  \n",
       "2                      So why they making a big deal          0  \n",
       "3  There’s nothing that makes it any better. We h...          0  \n",
       "4  Simply put, fascism needs to be fought against...          0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datapath = f'../data/comments_anonymous.csv'\n",
    "df = pd.read_csv(datapath)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab965eff-e1eb-416f-b80c-850554d8026c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='offensive'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby(['offensive']).size().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5074c270-ed3e-4e1a-863d-71737c743cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "labels = {'offensive':1,\n",
    "          'notoffensive':0\n",
    "          }\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, df):\n",
    "\n",
    "        self.labels = {0,0}\n",
    "        self.texts = [tokenizer(text, \n",
    "                               padding='max_length', max_length = 512, truncation=True,\n",
    "                                return_tensors=\"pt\") for text in df['comment']]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def get_batch_labels(self, idx):\n",
    "        # Fetch a batch of labels\n",
    "        return np.array(self.labels[idx])\n",
    "\n",
    "    def get_batch_texts(self, idx):\n",
    "        # Fetch a batch of inputs\n",
    "        return self.texts[idx]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c8a5d0f-80c3-42b3-9f06-ecfc3a21f395",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self, dropout=0.5):\n",
    "\n",
    "        super(BertClassifier, self).__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 5)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, input_id, mask):\n",
    "\n",
    "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fa1f1cf7-65db-4966-9a55-ba26bd22ed6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data, val_data, learning_rate, epochs):\n",
    "\n",
    "    train, val = Dataset(train_data), Dataset(val_data)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "            model = model.cuda()\n",
    "            criterion = criterion.cuda()\n",
    "\n",
    "    for epoch_num in range(epochs):\n",
    "\n",
    "            total_acc_train = 0\n",
    "            total_loss_train = 0\n",
    "\n",
    "            for train_input, train_label in tqdm(train_dataloader):\n",
    "\n",
    "                train_label = train_label.to(device)\n",
    "                mask = train_input['attention_mask'].to(device)\n",
    "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                output = model(input_id, mask)\n",
    "                \n",
    "                batch_loss = criterion(output, train_label.long())\n",
    "                total_loss_train += batch_loss.item()\n",
    "                \n",
    "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
    "                total_acc_train += acc\n",
    "\n",
    "                model.zero_grad()\n",
    "                batch_loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "            total_acc_val = 0\n",
    "            total_loss_val = 0\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                for val_input, val_label in val_dataloader:\n",
    "\n",
    "                    val_label = val_label.to(device)\n",
    "                    mask = val_input['attention_mask'].to(device)\n",
    "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "                    output = model(input_id, mask)\n",
    "\n",
    "                    batch_loss = criterion(output, val_label.long())\n",
    "                    total_loss_val += batch_loss.item()\n",
    "                    \n",
    "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
    "                    total_acc_val += acc\n",
    "            \n",
    "            print(\n",
    "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd8a670d-c449-45fe-8f4c-9a5fb27855c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_data):\n",
    "\n",
    "    test = Dataset(test_data)\n",
    "\n",
    "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "\n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "    if use_cuda:\n",
    "\n",
    "        model = model.cuda()\n",
    "\n",
    "    total_acc_test = 0\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for test_input, test_label in test_dataloader:\n",
    "\n",
    "              test_label = test_label.to(device)\n",
    "              mask = test_input['attention_mask'].to(device)\n",
    "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
    "\n",
    "              output = model(input_id, mask)\n",
    "\n",
    "              acc = (output.argmax(dim=1) == test_label).sum().item()\n",
    "              total_acc_test += acc\n",
    "    \n",
    "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25d2231d-fef1-42cf-a73e-188cac932727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3612 452 452\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(112)\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=42), \n",
    "                                     [int(.8*len(df)), int(.9*len(df))])\n",
    "\n",
    "print(len(df_train),len(df_val), len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30242239-de70-4c03-8f56-9f5ade43518d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'set' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2356/3725872795.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mLR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1e-6\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2356/3973615980.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, train_data, val_data, learning_rate, epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtotal_loss_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mtrain_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mtrain_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cooka\\anaconda3\\envs\\pytorch\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1180\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m                 \u001b[1;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 \u001b[1;31m# Update and possibly print the progressbar.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cooka\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cooka\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cooka\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\cooka\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2356/1647557199.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mbatch_texts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mbatch_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mbatch_texts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2356/1647557199.py\u001b[0m in \u001b[0;36mget_batch_labels\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_batch_labels\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[1;31m# Fetch a batch of labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_batch_texts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'set' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "              \n",
    "train(model, df_train, df_val, LR, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc00f0a-9a15-4942-9c9b-2f9789c8dd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, df_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "896d00145c3dbb933880c1cacb66f32680864d305420066baba40894f7ef51cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
