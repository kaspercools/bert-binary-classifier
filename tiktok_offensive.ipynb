{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## thanks to Nicolo \n",
    "https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894#8f53\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tiktok_text_processing\n",
    "import ml_utils\n",
    "\n",
    "from tabulate import tabulate\n",
    "from tqdm import trange\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62cfdd36dcebc86793aa9534</td>\n",
       "      <td>bro im not aa im literally african my tribe co...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62cfdda0dcebc86793aaee87</td>\n",
       "      <td>It drives me crazy! It’s such a struggle eithe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62cfde28dcebc86793ab60dc</td>\n",
       "      <td>So why they making a big deal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62cfdd8bdcebc86793aadc15</td>\n",
       "      <td>There’s nothing that makes it any better. We h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62cfddacdcebc86793aaf7bf</td>\n",
       "      <td>Simply put, fascism needs to be fought against...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  62cfdd36dcebc86793aa9534   \n",
       "1  62cfdda0dcebc86793aaee87   \n",
       "2  62cfde28dcebc86793ab60dc   \n",
       "3  62cfdd8bdcebc86793aadc15   \n",
       "4  62cfddacdcebc86793aaf7bf   \n",
       "\n",
       "                                             comment  offensive  \n",
       "0  bro im not aa im literally african my tribe co...          0  \n",
       "1  It drives me crazy! It’s such a struggle eithe...          0  \n",
       "2                      So why they making a big deal          0  \n",
       "3  There’s nothing that makes it any better. We h...          0  \n",
       "4  Simply put, fascism needs to be fought against...          0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = '../data/comments_anonymous.csv'\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comment'] = df['comment'].apply(ml_utils.remove_links)\n",
    "df['comment'] = df['comment'].apply(tiktok_text_processing.replace_slang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>offensive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62cfdd36dcebc86793aa9534</td>\n",
       "      <td>bro im not aa im lossiteralosslossy african my...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62cfdda0dcebc86793aaee87</td>\n",
       "      <td>It drives me crazy! It’s such a strugglosse ei...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62cfde28dcebc86793ab60dc</td>\n",
       "      <td>So winhy they making a big dealoss</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62cfdd8bdcebc86793aadc15</td>\n",
       "      <td>There’s nothing that makes it any better. We h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62cfddacdcebc86793aaf7bf</td>\n",
       "      <td>Simplossy put, fascism needs to be fought agai...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  62cfdd36dcebc86793aa9534   \n",
       "1  62cfdda0dcebc86793aaee87   \n",
       "2  62cfde28dcebc86793ab60dc   \n",
       "3  62cfdd8bdcebc86793aadc15   \n",
       "4  62cfddacdcebc86793aaf7bf   \n",
       "\n",
       "                                             comment  offensive  \n",
       "0  bro im not aa im lossiteralosslossy african my...          0  \n",
       "1  It drives me crazy! It’s such a strugglosse ei...          0  \n",
       "2                 So winhy they making a big dealoss          0  \n",
       "3  There’s nothing that makes it any better. We h...          0  \n",
       "4  Simplossy put, fascism needs to be fought agai...          0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "comments  = df.comment.values\n",
    "labels = df.offensive.values\n",
    "df.groupby(['offensive']).size().plot.bar()\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "We use bert-base-uncased because most comments don't use capital letters for NE + we are not interested in NER (Named enity recognition) anyway"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    do_lower_case = True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tiktok_text_processing' has no attribute 'add_emoji'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19040/3857550200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtiktok_text_processing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_emoji\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tiktok_text_processing' has no attribute 'add_emoji'"
     ]
    }
   ],
   "source": [
    "tiktok_text_processing.add_emoji_tokens(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════╤═════════════╕\n",
      "│ Tokens   │   Token IDs │\n",
      "╞══════════╪═════════════╡\n",
      "│ al       │        2632 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##oss    │       15094 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##los    │       10483 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##s      │        2015 │\n",
      "├──────────┼─────────────┤\n",
      "│ loss     │        3279 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##ives   │       24653 │\n",
      "├──────────┼─────────────┤\n",
      "│ matter   │        3043 │\n",
      "├──────────┼─────────────┤\n",
      "│ win      │        2663 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##as     │        3022 │\n",
      "├──────────┼─────────────┤\n",
      "│ a        │        1037 │\n",
      "├──────────┼─────────────┤\n",
      "│ saying   │        3038 │\n",
      "├──────────┼─────────────┤\n",
      "│ made     │        2081 │\n",
      "├──────────┼─────────────┤\n",
      "│ to       │        2000 │\n",
      "├──────────┼─────────────┤\n",
      "│ de       │        2139 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##grade  │       24170 │\n",
      "├──────────┼─────────────┤\n",
      "│ b        │        1038 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##los    │       10483 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##sack   │       25607 │\n",
      "├──────────┼─────────────┤\n",
      "│ loss     │        3279 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##ives   │       24653 │\n",
      "├──────────┼─────────────┤\n",
      "│ matter   │        3043 │\n",
      "├──────────┼─────────────┤\n",
      "│ ,        │        1010 │\n",
      "├──────────┼─────────────┤\n",
      "│ your     │        2115 │\n",
      "├──────────┼─────────────┤\n",
      "│ racism   │       14398 │\n",
      "├──────────┼─────────────┤\n",
      "│ re       │        2128 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##ek     │        5937 │\n",
      "├──────────┼─────────────┤\n",
      "│ ##s      │        2015 │\n",
      "╘══════════╧═════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence():\n",
    "  '''Displays the tokens and respective IDs of a random text sample'''\n",
    "  index = random.randint(0, len(comments)-1)\n",
    "  table = np.array([tokenizer.tokenize(comments[index]), \n",
    "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(comments[index]))]).T\n",
    "  print(tabulate(table,\n",
    "                 headers = ['Tokens', 'Token IDs'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70.69555610115394\n",
      "70.69555610115394\n",
      "322\n"
     ]
    }
   ],
   "source": [
    "comment_lenghts = [len(comment) for comment in comments]\n",
    "comment_len_mean = np.mean(comment_lenghts)\n",
    "comment_len_avg = np.average(comment_lenghts)\n",
    "comment_max_len = np.max(comment_lenghts)\n",
    "\n",
    "print(comment_len_avg)\n",
    "print(comment_len_mean)\n",
    "print(comment_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max sentence length:  322\n"
     ]
    }
   ],
   "source": [
    "print('Max sentence length: ', max([len(comment) for comment in comments]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_id = []\n",
    "attention_masks = []\n",
    "\n",
    "def preprocessing(input_text, tokenizer):\n",
    "  '''\n",
    "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "    - input_ids: list of token ids\n",
    "    - token_type_ids: list of token type ids\n",
    "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
    "  '''\n",
    "  return tokenizer.encode_plus(\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = comment_max_len,\n",
    "                        pad_to_max_length = True,\n",
    "                        padding='max_length',\n",
    "                        return_attention_mask = True,\n",
    "                        truncation = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "\n",
    "\n",
    "for sample in comments:\n",
    "  encoding_dict = preprocessing(sample, tokenizer)\n",
    "  token_id.append(encoding_dict['input_ids']) \n",
    "  attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "token_id = torch.cat(token_id, dim = 0)\n",
    "attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "labels = torch.tensor(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  2273, 25931, 15094, 10483,  2015,  2031,  2062, 14163, 11020,\n",
       "        10483,  3366,  3742,  1010,  1998,  2006,  2779,  2024,  6428,   102,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_id[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒══════════╤═════════════╤══════════════════╕\n",
      "│ Tokens   │   Token IDs │   Attention Mask │\n",
      "╞══════════╪═════════════╪══════════════════╡\n",
      "│ [CLS]    │         101 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ dude     │       12043 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ cried    │        6639 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ in       │        1999 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ court    │        2457 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ for      │        2005 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ getting  │        2893 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ loss     │        3279 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ ##ike    │       17339 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ 3        │        1017 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ months   │        2706 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ in       │        1999 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ jail     │        7173 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ ##oss    │       15094 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [UNK]    │         100 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [SEP]    │         102 │                1 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "├──────────┼─────────────┼──────────────────┤\n",
      "│ [PAD]    │           0 │                0 │\n",
      "╘══════════╧═════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "def print_rand_sentence_encoding():\n",
    "  '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
    "  index = random.randint(0, len(comments) - 1)\n",
    "  tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
    "  token_ids = [i.numpy() for i in token_id[index]]\n",
    "  attention = [i.numpy() for i in attention_masks[index]]\n",
    "\n",
    "  table = np.array([tokens, token_ids, attention]).T\n",
    "  print(tabulate(table, \n",
    "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
    "                 tablefmt = 'fancy_grid'))\n",
    "\n",
    "print_rand_sentence_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines ratios, w.r.t. whole dataset.\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "test_ratio = 0.15\n",
    "\n",
    "# Recommended batch size: 16, 32. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "batch_size = 8\n",
    "\n",
    "# Indices of the train and validation splits stratified by labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels)\n",
    "\n",
    "#new_test_ratio = np.around(test_ratio / (val_ratio + test_ratio), 2)\n",
    "# To preserve (new_test_ratio + new_val_ratio) = 1.0 \n",
    "#new_val_ratio = 1.0 - new_test_ratio\n",
    "\n",
    "#val_idx, test_idx = train_test_split(remain_idx, test_size=new_test_ratio)\n",
    "\n",
    "# Train and validation sets\n",
    "train_set = TensorDataset(token_id[train_idx], \n",
    "                          attention_masks[train_idx], \n",
    "                          labels[train_idx])\n",
    "\n",
    "val_set = TensorDataset(token_id[val_idx], \n",
    "                        attention_masks[val_idx], \n",
    "                        labels[val_idx])\n",
    "\n",
    "#test_set = TensorDataset(token_id[test_idx], \n",
    " #                       attention_masks[test_idx], \n",
    "  #                      labels[test_idx])\n",
    "\n",
    "\n",
    "# Prepare DataLoader\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,\n",
    "            sampler = RandomSampler(train_set),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_set,\n",
    "            sampler = SequentialSampler(val_set),\n",
    "            batch_size = batch_size\n",
    "        )\n",
    "\n",
    "#test_dataloader = DataLoader(\n",
    " #           test_set,\n",
    "  #          sampler = SequentialSampler(test_set),\n",
    "   #         batch_size = batch_size\n",
    "    #    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def b_tp(preds, labels):\n",
    "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
    "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fp(preds, labels):\n",
    "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
    "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_tn(preds, labels):\n",
    "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
    "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_fn(preds, labels):\n",
    "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
    "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
    "\n",
    "def b_metrics(preds, labels):\n",
    "  '''\n",
    "  Returns the following metrics:\n",
    "    - accuracy    = (TP + TN) / N\n",
    "    - precision   = TP / (TP + FP)\n",
    "    - recall      = TP / (TP + FN)\n",
    "    - specificity = TN / (TN + FP)\n",
    "  '''\n",
    "  preds = np.argmax(preds, axis = 1).flatten()\n",
    "  labels = labels.flatten()\n",
    "  tp = b_tp(preds, labels)\n",
    "  tn = b_tn(preds, labels)\n",
    "  fp = b_fp(preds, labels)\n",
    "  fn = b_fn(preds, labels)\n",
    "  b_accuracy = (tp + tn) / len(labels)\n",
    "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
    "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
    "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
    "  return b_accuracy, b_precision, b_recall, b_specificity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# clear cache on re-run\n",
    "import torch, gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Load the BertForSequenceClassification model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels = 2,\n",
    "    output_attentions = False,\n",
    "    output_hidden_states = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "optimizer = torch.optim.AdamW(model.parameters(), \n",
    "                              lr = 5e-5,\n",
    "                              eps = 1e-08\n",
    "                              )\n",
    "\n",
    "# Run on GPU\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 1/3 [03:14<06:28, 194.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.5587\n",
      "\t - Validation Accuracy: 0.7719\n",
      "\t - Validation Precision: 0.7332\n",
      "\t - Validation Recall: 0.8855\n",
      "\t - Validation Specificity: 0.6638\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 2/3 [06:27<03:13, 193.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.3412\n",
      "\t - Validation Accuracy: 0.7756\n",
      "\t - Validation Precision: 0.8760\n",
      "\t - Validation Recall: 0.6473\n",
      "\t - Validation Specificity: 0.9127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [09:40<00:00, 193.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\t - Train loss: 0.1877\n",
      "\t - Validation Accuracy: 0.7694\n",
      "\t - Validation Precision: 0.7210\n",
      "\t - Validation Recall: 0.8749\n",
      "\t - Validation Specificity: 0.6952\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
    "epochs = 3\n",
    "\n",
    "training_results=[]\n",
    "\n",
    "for _ in trange(epochs, desc = 'Epoch'):\n",
    "    \n",
    "    # ========== Training ==========\n",
    "    \n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "    \n",
    "    # Tracking variables\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        train_output = model(b_input_ids, \n",
    "                             token_type_ids = None, \n",
    "                             attention_mask = b_input_mask, \n",
    "                             labels = b_labels)\n",
    "        # Backward pass\n",
    "        train_output.loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update tracking variables\n",
    "        tr_loss += train_output.loss.item()\n",
    "        nb_tr_examples += b_input_ids.size(0)\n",
    "        nb_tr_steps += 1\n",
    "\n",
    "    # ========== Validation ==========\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "        \n",
    "    val_accuracy = []\n",
    "    val_precision = []\n",
    "    val_recall = []\n",
    "    val_specificity = []\n",
    "\n",
    "    for batch in validation_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "          # Forward pass\n",
    "          eval_output = model(b_input_ids, \n",
    "                              token_type_ids = None, \n",
    "                              attention_mask = b_input_mask)\n",
    "        logits = eval_output.logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        # Calculate validation metrics\n",
    "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
    "        val_accuracy.append(b_accuracy)\n",
    "        # Update precision only when (tp + fp) !=0; ignore nan\n",
    "        if b_precision != 'nan': val_precision.append(b_precision)\n",
    "        # Update recall only when (tp + fn) !=0; ignore nan\n",
    "        if b_recall != 'nan': val_recall.append(b_recall)\n",
    "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
    "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
    "\n",
    "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
    "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n",
    "    training_results.append({\n",
    "        'accuracy':'{:.4f}'.format(sum(val_accuracy)/len(val_accuracy)),\n",
    "        'precision':'{:.4f}'.format(sum(val_precision)/len(val_precision)),\n",
    "        'recall':'{:.4f}'.format(sum(val_recall)/len(val_recall)),\n",
    "        'specificity':'{:.4f}'.format(sum(val_specificity)/len(val_specificity))\n",
    "    })\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accuracy': '0.7792',\n",
       "  'precision': '0.7467',\n",
       "  'recall': '0.8650',\n",
       "  'specificity': '0.7039'},\n",
       " {'accuracy': '0.7841',\n",
       "  'precision': '0.8792',\n",
       "  'recall': '0.6648',\n",
       "  'specificity': '0.9133'},\n",
       " {'accuracy': '0.7904',\n",
       "  'precision': '0.8171',\n",
       "  'recall': '0.7505',\n",
       "  'specificity': '0.8377'}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence:  How do you make a dead coon float? Take your foot off its head and let it rise to the surface asshole\n",
      "Predicted Class:  Offensive\n"
     ]
    }
   ],
   "source": [
    "new_sentence = 'How do you make a dead coon float? Take your foot off its head and let it rise to the surface asshole'\n",
    "\n",
    "# We need Token IDs and Attention Mask for inference on the new sentence\n",
    "test_ids = []\n",
    "test_attention_mask = []\n",
    "\n",
    "# Apply the tokenizer\n",
    "encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "test_ids.append(encoding['input_ids'])\n",
    "test_attention_mask.append(encoding['attention_mask'])\n",
    "test_ids = torch.cat(test_ids, dim = 0)\n",
    "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "\n",
    "# Forward pass, calculate logit predictions\n",
    "with torch.no_grad():\n",
    "  output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
    "\n",
    "prediction = 'Offensive' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'Not offensive'\n",
    "\n",
    "print('Input Sentence: ', new_sentence)\n",
    "print('Predicted Class: ', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sentence:  cap\n",
      "Predicted Class:  Offensive\n"
     ]
    }
   ],
   "source": [
    "new_sentence = \"cap\"\n",
    "\n",
    "# We need Token IDs and Attention Mask for inference on the new sentence\n",
    "test_ids = []\n",
    "test_attention_mask = []\n",
    "\n",
    "# Apply the tokenizer\n",
    "encoding = preprocessing(new_sentence, tokenizer)\n",
    "\n",
    "# Extract IDs and Attention Mask\n",
    "test_ids.append(encoding['input_ids'])\n",
    "test_attention_mask.append(encoding['attention_mask'])\n",
    "test_ids = torch.cat(test_ids, dim = 0)\n",
    "test_attention_mask = torch.cat(test_attention_mask, dim = 0)\n",
    "\n",
    "# Forward pass, calculate logit predictions\n",
    "with torch.no_grad():\n",
    "  output = model(test_ids.to(device), token_type_ids = None, attention_mask = test_attention_mask.to(device))\n",
    "\n",
    "prediction = 'Offensive' if np.argmax(output.logits.cpu().numpy()).flatten().item() == 1 else 'Not offensive'\n",
    "\n",
    "print('Input Sentence: ', new_sentence)\n",
    "print('Predicted Class: ', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'accuracy': '0.7792',\n",
       "  'precision': '0.7467',\n",
       "  'recall': '0.8650',\n",
       "  'specificity': '0.7039'},\n",
       " {'accuracy': '0.7841',\n",
       "  'precision': '0.8792',\n",
       "  'recall': '0.6648',\n",
       "  'specificity': '0.9133'},\n",
       " {'accuracy': '0.7904',\n",
       "  'precision': '0.8171',\n",
       "  'recall': '0.7505',\n",
       "  'specificity': '0.8377'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestr = time.strftime(\"%Y%m%d_%H%M%S\")\n",
    "#todo save results as well\n",
    "torch.save(model.state_dict(),'models/'+timestr+'_offensive.bak')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# Serializing json\n",
    "json_object = json.dumps(training_results, indent=4)\n",
    " \n",
    "# Writing to sample.json\n",
    "with open('models/'+timestr + \"offensive.json\", \"w\") as outfile:\n",
    "    outfile.write(json_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "896d00145c3dbb933880c1cacb66f32680864d305420066baba40894f7ef51cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
